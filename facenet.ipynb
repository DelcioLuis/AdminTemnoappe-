{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facenet.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DelcioLuis/AdminTemnoappe-/blob/master/facenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet-pytorch\n",
        "!pip install albumentations\n",
        "\n",
        "# !pip install tensorflow==2.12.0 # Certifique-se de instalar a versão correta do TensorFlow"
      ],
      "metadata": {
        "id": "WVC4x-LZa9JZ",
        "outputId": "54719a6e-0534-44e0-dc71-3499329ece82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.26.4)\n",
            "Collecting Pillow<10.3.0,>=10.2.0 (from facenet-pytorch)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Collecting torch<2.3.0,>=2.2.0 (from facenet-pytorch)\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch)\n",
            "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (4.66.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
            "Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, facenet-pytorch\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 10.4.0\n",
            "    Uninstalling pillow-10.4.0:\n",
            "      Successfully uninstalled pillow-10.4.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.0+cu121\n",
            "    Uninstalling torchvision-0.20.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.2.0 facenet-pytorch-2.6.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2 triton-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "76f01b3ea00f4d6898e12c6a29839315"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.9.2)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LQU3VKqOATo",
        "outputId": "20e6e3f6-07b4-4d21-d894-eb65ccf2c159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvsZ05l2X2Lk"
      },
      "source": [
        "**Define function-helpers for data preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fedZOaDJX-j3"
      },
      "source": [
        "**Define image path**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ifHfoHOARr"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "\n",
        "def get_files(path='./', ext=('.png', '.jpeg', '.jpg')):\n",
        "    \"\"\" Get all image files and sort them by the number in their name \"\"\"\n",
        "    files = []\n",
        "    for e in ext:\n",
        "        files.extend(glob.glob(f'{path}/**/*{e}', recursive=True))\n",
        "    files.sort(key=lambda p: (os.path.dirname(p), extract_number(os.path.basename(p))))\n",
        "    return files\n",
        "\n",
        "def extract_number(filename):\n",
        "    \"\"\" Extract number from filename, default to 0 if no number is found \"\"\"\n",
        "    match = re.search(r'(\\d+)(?=\\.\\w+$)', filename)  # Find number before the extension\n",
        "    return int(match.group(1)) if match else 0\n",
        "\n",
        "\n",
        "def to_rgb_and_save(path):\n",
        "    \"\"\" Some of the images may have RGBA mode \"\"\"\n",
        "    for p in path:\n",
        "        img = Image.open(p)\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "            img.save(p)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDfRtYNAYMhk"
      },
      "source": [
        "ABS_PATH = '/content/drive/My Drive/treinomodelo/'\n",
        "DATA_PATH = os.path.join(ABS_PATH, 'data')\n",
        "\n",
        "TRAIN_DIR = os.path.join(DATA_PATH, 'treino')\n",
        "TEST_DIR = os.path.join(DATA_PATH, 'teste')\n",
        "\n",
        "ALIGNED_TRAIN_DIR = TRAIN_DIR + '_cropped'\n",
        "ALIGNED_TEST_DIR = TEST_DIR + '_cropped'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8csu2Gs-cx7O"
      },
      "source": [
        "**Preparing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHA_VX-vOAP2",
        "outputId": "7c4f5cb3-dba4-4b22-f1a5-e3eab7a8e00f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "# 1. Get path for TRAIN_DIR/TEST_DIR\n",
        "trainF, testF = get_files(TRAIN_DIR), get_files(TEST_DIR)\n",
        "\n",
        "# prepare info for printing\n",
        "trainC, testC = Counter(map(os.path.dirname, trainF)), Counter(map(os.path.dirname, testF))\n",
        "train_total, train_text  = sum(trainC.values()), '\\n'.join([f'\\t- {os.path.basename(fp)} - {c}' for fp, c in trainC.items()])\n",
        "test_total, test_text  = sum(testC.values()), '\\n'.join([f'\\t- {os.path.basename(fp)} - {c}' for fp, c in testC.items()])\n",
        "\n",
        "print(f'Train files\\n\\tpath: {TRAIN_DIR}\\n\\ttotal number: {train_total}\\n{train_text}')\n",
        "print(f'Train files\\n\\tpath: {TEST_DIR}\\n\\ttotal number: {test_total}\\n{test_text}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train files\n",
            "\tpath: /content/drive/My Drive/modelos/data/treino\n",
            "\ttotal number: 3945\n",
            "\t- Abah Festus - 8\n",
            "\t- Abay Tsehaye - 8\n",
            "\t- Abdelaziz Bouteflika - 8\n",
            "\t- Abdelaziz Djerad - 8\n",
            "\t- Abdelmadjid Tebboune - 8\n",
            "\t- Abebaw butako - 8\n",
            "\t- Abedi Pele - 8\n",
            "\t- Abel Edime - 8\n",
            "\t- Abosede Olajide - 8\n",
            "\t- Abubeker Nassir - 8\n",
            "\t- Abuya Solomon - 8\n",
            "\t- Adam Bombolb - 8\n",
            "\t- Adam Ounas - 8\n",
            "\t- Adane Girma - 8\n",
            "\t- Adebimpe Olarewaju - 8\n",
            "\t- Adedini Adeola - 8\n",
            "\t- Adegoke Akinyele - 8\n",
            "\t- Adegoke Olamide - 8\n",
            "\t- Adem Zorgane - 8\n",
            "\t- Adesua Etomi - 8\n",
            "\t- Adigun Pelumi - 8\n",
            "\t- Agostinho Kapaia - 8\n",
            "\t- Ahmed Ben Bella - 8\n",
            "\t- Ahmed Elmohamady - 8\n",
            "\t- Ahmed Hegazi - 8\n",
            "\t- Ahmed Kathrada - 8\n",
            "\t- Ahmed Magdy - 8\n",
            "\t- Ahmed Mahgoub - 8\n",
            "\t- Ahmed Mazouz - 8\n",
            "\t- Ahmed Sayed - 8\n",
            "\t- Ahmed saad - 8\n",
            "\t- Ajewole Fasanmi Richard - 8\n",
            "\t- Ajewole Olaitan - 8\n",
            "\t- Akua Dansua - 8\n",
            "\t- Akwa - 8\n",
            "\t- Aladeokin A. Abiodun - 8\n",
            "\t- Albert Luthuli - 8\n",
            "\t- Alemu Aga - 8\n",
            "\t- Alula Girma - 8\n",
            "\t- Amin Askar - 8\n",
            "\t- AminB - 8\n",
            "\t- Amira Selim - 8\n",
            "\t- Amos Wako - 8\n",
            "\t- Amr Waked - 8\n",
            "\t- Andre Ayew - 8\n",
            "\t- Andre Gaspar Mendes de Carvalho - 8\n",
            "\t- Anifowose Mariam - 8\n",
            "\t- Anoushka - 8\n",
            "\t- Anssa Mandi - 8\n",
            "\t- Antanio Mendona - 8\n",
            "\t- Antjie Krog - 8\n",
            "\t- Anton Rupert - 8\n",
            "\t- Anuoluwapo Comfort Kolawole - 8\n",
            "\t- Aristote Nsiala - 8\n",
            "\t- Arlindo Barbeitos - 8\n",
            "\t- Arthur Masuaku - 8\n",
            "\t- Ary Papel - 2\n",
            "\t- Asamoah Gyan - 8\n",
            "\t- Aster Aweke - 8\n",
            "\t- Avril - 8\n",
            "\t- Babatunde Oladogba - 8\n",
            "\t- Basetsana Kumalo - 8\n",
            "\t- Becca - 8\n",
            "\t- Behailu Assefa - 8\n",
            "\t- Behati Prinsloo - 8\n",
            "\t- Bela - 8\n",
            "\t- Ben Malango - 8\n",
            "\t- Ben Ulenga - 8\n",
            "\t- Ben Youcef - 8\n",
            "\t- Benjamin Hauwanga - 8\n",
            "\t- Benjamin Ochieng - 8\n",
            "\t- Benson Shilongo - 8\n",
            "\t- Berhane Gebrekiristos - 8\n",
            "\t- Bertrand Bisimwa - 8\n",
            "\t- Bethlehem Tilahun Alemu - 8\n",
            "\t- Beverly Naya - 8\n",
            "\t- Beyers Naude - 8\n",
            "\t- Bience Gawanas - 8\n",
            "\t- Bill Asamoah - 8\n",
            "\t- Bill Sellanga - 8\n",
            "\t- Birtukan Mideksa - 8\n",
            "\t- Bishop David Abioye - 8\n",
            "\t- Bishop David Oyedepo - 8\n",
            "\t- Black Sherif - 8\n",
            "\t- Bodunha - 8\n",
            "\t- Bonginkosi Dlamini - 8\n",
            "\t- Bozi Boziana - 8\n",
            "\t- Branca Manuel Espirito Santo - 8\n",
            "\t- Brenda Fassie - 8\n",
            "\t- Brenda Wairimu - 8\n",
            "\t- Britier - 8\n",
            "\t- Buhari - 8\n",
            "\t- C. Manuel Cafumana - 8\n",
            "\t- Carlos Conceicao - 8\n",
            "\t- Carmen Suleiman - 8\n",
            "\t- Carolina Cerqueira - 8\n",
            "\t- Catherine Kamau - 8\n",
            "\t- Cedric Bakambu - 8\n",
            "\t- Celso Roberto - 8\n",
            "\t- Chadli Bendjedid - 8\n",
            "\t- Chahrazad Kracheni - 8\n",
            "\t- Chancel Mbemba Mangulu - 8\n",
            "\t- Chara - 8\n",
            "\t- Charlize Theron - 8\n",
            "\t- Cheb Hamidou - 8\n",
            "\t- Cheb Rami - 8\n",
            "\t- Cheb Reda Diamond - 8\n",
            "\t- Chinua Achebe - 8\n",
            "\t- Chris Attoh - 8\n",
            "\t- Chris Hani - 8\n",
            "\t- Chris Kirubi - 8\n",
            "\t- Christabel Ekeh - 8\n",
            "\t- Christian Atsu - 8\n",
            "\t- Christian Luyindama - 8\n",
            "\t- Christian Malanga - 2\n",
            "\t- Christianah Oyewale - 8\n",
            "\t- Christine Wawira - 8\n",
            "\t- Claude Wilfrid Etoka - 8\n",
            "\t- Clemens Kapuuo - 8\n",
            "\t- Collin Benjamin - 8\n",
            "\t- Coussoud-Mavoungou - 8\n",
            "\t- Cyril Ramaphosa - 8\n",
            "\t- Dadju - 8\n",
            "\t- Damilola - 8\n",
            "\t- Damilola Orimolade - 8\n",
            "\t- Daniel Amartey - 8\n",
            "\t- Daniel Aselo Okito - 8\n",
            "\t- Daniel Francois Malan - 8\n",
            "\t- Daniel McKorley - 8\n",
            "\t- Daniel arap Moi - 8\n",
            "\t- Danny Jordaan - 8\n",
            "\t- David Ndjavera - 8\n",
            "\t- Degu Debebe - 8\n",
            "\t- Demeke Mekonnen - 8\n",
            "\t- Denzil Haoseb - 8\n",
            "\t- Deon Kavendji - 8\n",
            "\t- Desmond Tutu - 8\n",
            "\t- Didi Stone Olomide - 8\n",
            "\t- Dieudonne Ndinga Moukala - 8\n",
            "\t- Djalma Campos - 8\n",
            "\t- Don Jazzy - 8\n",
            "\t- Dullah Omar - 8\n",
            "\t- Eddie Kadi - 8\n",
            "\t- Eddie Nartey - 8\n",
            "\t- Edi Gathegi - 8\n",
            "\t- Egas Cacintura - 8\n",
            "\t- Elijah Lagat - 8\n",
            "\t- Elijah Ngurare - 8\n",
            "\t- Elizabeth Ohene - 8\n",
            "\t- Elizabeth Teissier - 8\n",
            "\t- Ephrem Amare - 8\n",
            "\t- Eric Wainaina - 8\n",
            "\t- Erica Chissapa - 8\n",
            "\t- Ermias Amelga - 8\n",
            "\t- Eshele Botende - 8\n",
            "\t- Eslin Kamuhanga - 8\n",
            "\t- Essam El-Hadary - 8\n",
            "\t- Eugkne Terre Blanche - 8\n",
            "\t- Evoloko Jocker - 8\n",
            "\t- Ewatomi - 8\n",
            "\t- Ezenwo Nyesom Wike - 8\n",
            "\t- F. W. de Klerk - 8\n",
            "\t- Fatima Meer - 8\n",
            "\t- Felix Afena-Gyan - 8\n",
            "\t- Femi - 8\n",
            "\t- Fethi Manar - 8\n",
            "\t- Fikru Teferra - 8\n",
            "\t- Flavo Amado - 8\n",
            "\t- Frank Acheampong - 8\n",
            "\t- Frank Artus - 8\n",
            "\t- Frankie Fredericks - 8\n",
            "\t- Fredy - 8\n",
            "\t- Fuad Ibrahim - 8\n",
            "\t- GaNl Kakuta - 8\n",
            "\t- Gary Player - 8\n",
            "\t- Gatoch Panom - 8\n",
            "\t- Gedeon Kalulu - 8\n",
            "\t- Gelila Bekele - 8\n",
            "\t- Gelson Dala - 8\n",
            "\t- Getaneh Kebede - 8\n",
            "\t- Gideon Mensah - 8\n",
            "\t- Girley Jazama - 8\n",
            "\t- Godwin Obaseki - 8\n",
            "\t- Grace Ogot - 8\n",
            "\t- Guilherme Afonso - 8\n",
            "\t- Hage Geingob - 8\n",
            "\t- Haile Gebrselassie - 8\n",
            "\t- Hamdi Fathi - 8\n",
            "\t- Hanan Tarq - 8\n",
            "\t- Hany Ramzy - 8\n",
            "\t- Happiness - 8\n",
            "\t- Haris Belkebla - 8\n",
            "\t- Harry Simon - 8\n",
            "\t- Hassan Kachach - 8\n",
            "\t- Heino Senekal - 8\n",
            "\t- Helalia Johannes - 8\n",
            "\t- Helder Costa - 8\n",
            "\t- Helen Suzman - 8\n",
            "\t- Hendrik Somaeb - 8\n",
            "\t- Hendrik Verwoerd - 8\n",
            "\t- Hicham Boudaoui - 8\n",
            "\t- Hossam Habib - 8\n",
            "\t- Hossam Hassan - 8\n",
            "\t- Houari Boumediene - 8\n",
            "\t- Hussein El Shahat - 8\n",
            "\t- Imaye Taga - 7\n",
            "\t- Isaac Maria dos Anjos - 8\n",
            "\t- Isabel dos Santos - 8\n",
            "\t- IsmaNl Bennacer - 8\n",
            "\t- J. R. R. Tolkien - 8\n",
            "\t- Jackie Appiah - 8\n",
            "\t- Jackson Muleka - 8\n",
            "\t- James Mwangi - 8\n",
            "\t- Jan du Toit - 8\n",
            "\t- Jawar Mohammed - 8\n",
            "\t- Jean Andeka - 8\n",
            "\t- Jean-Claude Bastos de Morais - 8\n",
            "\t- Jean-Pierre Bemba - 8\n",
            "\t- Jemal Tassew - 8\n",
            "\t- Jessica Beshir - 8\n",
            "\t- Jessy Matador - 8\n",
            "\t- Joao Baptista Borges - 8\n",
            "\t- Joao Lourenco - 8\n",
            "\t- Joaquim David - 8\n",
            "\t- Joe Slovo - 8\n",
            "\t- Joel Haikali - 8\n",
            "\t- Johann Rupert - 8\n",
            "\t- John Atta Mills - 8\n",
            "\t- John Dumelo - 7\n",
            "\t- Johnny Clegg - 8\n",
            "\t- Jomo Kenyatta - 8\n",
            "\t- Jonas Ramalho - 8\n",
            "\t- Jonathan Buatu - 8\n",
            "\t- Jonl Kimwaki - 8\n",
            "\t- Jonty Rhodes - 8\n",
            "\t- Jordan Ayew - 7\n",
            "\t- Jordan Botaka - 8\n",
            "\t- Jose Eduardo dos Santos - 8\n",
            "\t- Joseph Siaw Agyapong - 8\n",
            "\t- Josiah Mwangi Kariuki - 8\n",
            "\t- Josky Kiambukuta - 8\n",
            "\t- Juanita du Plessis - 8\n",
            "\t- Kader Japonais - 8\n",
            "\t- Kahush - 8\n",
            "\t- Kaizer Motaung - 8\n",
            "\t- Kaka Sungura - 8\n",
            "\t- Kali - 8\n",
            "\t- Kamel Belghazi - 8\n",
            "\t- Kamo Mphela - 8\n",
            "\t- Kayode - 8\n",
            "\t- Kehinde - 8\n",
            "\t- Kemi - 8\n",
            "\t- Kevin-Prince Boateng - 8\n",
            "\t- Khaligraph Jones - 8\n",
            "\t- Koigi wa Wamwere - 6\n",
            "\t- Kuami Eugene - 8\n",
            "\t- Kunleola Adebayo - 8\n",
            "\t- Kwadwo Asamoah - 8\n",
            "\t- Kwaku Manu - 8\n",
            "\t- Kwesi Arthur - 8\n",
            "\t- Lakhdar Brahimi - 8\n",
            "\t- Larbi Ben Mhid - 8\n",
            "\t- Lazarus Kaimbi - 8\n",
            "\t- Leon Schuster - 8\n",
            "\t- Liamine Zeroual - 8\n",
            "\t- Liya Kebede - 8\n",
            "\t- Loco - 4\n",
            "\t- Lord Paul Boateng - 8\n",
            "\t- Lucien Ebata - 8\n",
            "\t- Lydia Forson - 8\n",
            "\t- Lyes Salem - 8\n",
            "\t- Lyna Khoudri - 8\n",
            "\t- MBala Nzola - 7\n",
            "\t- Madilu System - 8\n",
            "\t- Mahder Assefa - 8\n",
            "\t- Mahmoud Hamdy - 8\n",
            "\t- Majid Michel - 6\n",
            "\t- Mama Ngina Kenyatta - 8\n",
            "\t- Mandoza - 8\n",
            "\t- Mangosuthu Buthelezi - 8\n",
            "\t- Manucho - 8\n",
            "\t- Marco Airosa - 8\n",
            "\t- Marcus Samuelsson - 8\n",
            "\t- Marie Daulne - 8\n",
            "\t- Mark Shuttleworth - 8\n",
            "\t- Marlice van Vuuren - 8\n",
            "\t- Martha Ankomah - 5\n",
            "\t- Mary Oyaya - 8\n",
            "\t- Mateus Galiano da Costa - 8\n",
            "\t- Mayowa Afolabi - 8\n",
            "\t- Mejja - 8\n",
            "\t- Mekonnen Knife - 3\n",
            "\t- Mercy Myra - 8\n",
            "\t- Merouane Guerouabi - 8\n",
            "\t- Merveille Bokadi - 8\n",
            "\t- Micaela Reis - 8\n",
            "\t- Michael Crichton - 8\n",
            "\t- Michael Essien - 7\n",
            "\t- Michael Kennedy Naiboi - 8\n",
            "\t- Michael Olunga - 8\n",
            "\t- Michelle McLean - 8\n",
            "\t- Mido - 8\n",
            "\t- Mike Ezuruonye - 8\n",
            "\t- Mike Sonko - 8\n",
            "\t- Milson - 8\n",
            "\t- Minyahil Teshome - 8\n",
            "\t- Miriam Makeba - 8\n",
            "\t- Mohamed Abdelmonem - 8\n",
            "\t- Mohamed Aboutrika - 8\n",
            "\t- Mohamed Elneny - 8\n",
            "\t- Mohamed Fares - 8\n",
            "\t- Mohamed Fayed - 8\n",
            "\t- Mohamed Hussein Tantawi - 8\n",
            "\t- Mohamed Laid Benamor - 8\n",
            "\t- Mohamed Magdy - 8\n",
            "\t- Mohamed Mansour - 8\n",
            "\t- Mohamed Salah - 8\n",
            "\t- Mohamed Sherif - 8\n",
            "\t- Mohamed Zidan - 8\n",
            "\t- Mohammed Al Amoudi - 8\n",
            "\t- Mohammed El Shenawy - 8\n",
            "\t- Mohammed Kudus - 8\n",
            "\t- Mohammed Ouseb - 8\n",
            "\t- Mohammed Salisu - 8\n",
            "\t- Moise Katumbi - 8\n",
            "\t- Mose Se Sengo - 3\n",
            "\t- Moses Wetangula - 8\n",
            "\t- Moshe Abebe - 8\n",
            "\t- Mostafa Fathi - 8\n",
            "\t- Mostafa Mohamed - 8\n",
            "\t- Mouni Bouallam - 8\n",
            "\t- Mourad Eulmi - 8\n",
            "\t- Muhammad Boudiaf - 8\n",
            "\t- Muluken Melesse - 8\n",
            "\t- Mustapha Laribi - 8\n",
            "\t- Mwai Kibaki - 8\n",
            "\t- Nader Ghabbour - 8\n",
            "\t- Nader Hamdy - 8\n",
            "\t- Nadia Buari - 7\n",
            "\t- Nadia Mukami - 8\n",
            "\t- Naguib Sawiris - 8\n",
            "\t- Nancy Isime - 8\n",
            "\t- Nancy Johannes - 8\n",
            "\t- Nassef Sawiris - 8\n",
            "\t- Nelson Mandela - 8\n",
            "\t- Nelson da Luz - 8\n",
            "\t- Neway Debebe - 8\n",
            "\t- Nhatty Man - 8\n",
            "\t- Nianell - 8\n",
            "\t- Nicholas Biwott - 8\n",
            "\t- Nick Mutumqa - 8\n",
            "\t- Nicole Garcia - 8\n",
            "\t- Nikita Kering - 8\n",
            "\t- Nixau Toma - 8\n",
            "\t- Nkosazana Dlamini-Zuma - 8\n",
            "\t- Nour El Sayed - 8\n",
            "\t- Nyashinski - 8\n",
            "\t- Obasanjo - 8\n",
            "\t- Okon Abosede Ola - 8\n",
            "\t- Okyeame Kwame - 8\n",
            "\t- Olagbende Ebenezer - 8\n",
            "\t- Olaku Temitope - 8\n",
            "\t- Oliver Litondo - 8\n",
            "\t- Oliver Risser - 8\n",
            "\t- Oliver Tambo - 8\n",
            "\t- Oluwaseyi Makinde - 8\n",
            "\t- Oluwatoyin Olajumoke - 8\n",
            "\t- Omar Marmoush - 8\n",
            "\t- Omenuke Mfulu - 8\n",
            "\t- Omer Ali Shifaw - 8\n",
            "\t- Onsi  Sawiris - 8\n",
            "\t- Oscar Maritu - 8\n",
            "\t- Otile Brown - 8\n",
            "\t- Oumed Oukri - 8\n",
            "\t- Owolabi Rukayat Adeshola - 8\n",
            "\t- Oyinkansola - 8\n",
            "\t- P. W. Botha - 8\n",
            "\t- Papa Wemba - 8\n",
            "\t- Pascal Tokodi - 8\n",
            "\t- Pastor Enoch Adeboye - 8\n",
            "\t- Patrice Motse - 8\n",
            "\t- Patricia de Lille - 8\n",
            "\t- Patsha Bay - 8\n",
            "\t- Paul Kruger - 8\n",
            "\t- Paulao - 8\n",
            "\t- Paulino Baptista - 8\n",
            "\t- Paulus Ambunda - 8\n",
            "\t- Percy Montgomery - 8\n",
            "\t- Peter Shalulile - 8\n",
            "\t- Pieter-Dirk Uys - 8\n",
            "\t- Prince David Osei - 8\n",
            "\t- Quinzinho - 8\n",
            "\t- Raila Odinga - 8\n",
            "\t- Ramy Bensebaini - 8\n",
            "\t- Ramy Gamal - 8\n",
            "\t- Ramy Sabry - 8\n",
            "\t- Raouf Ghabbour - 8\n",
            "\t- Raphael Soriano Katoto Katebe - 8\n",
            "\t- Ras Samuel Weldaabzgi - 8\n",
            "\t- Rasselas Lakew - 8\n",
            "\t- Ray Lema - 8\n",
            "\t- Raymond Ofula - 2\n",
            "\t- Razundara Tjikuzu - 8\n",
            "\t- Reggie Rockstone - 8\n",
            "\t- Richard Leakey - 8\n",
            "\t- Riyad Mahrez - 8\n",
            "\t- Robert Nauseb - 8\n",
            "\t- Robert Sobukwe - 8\n",
            "\t- Romand - 8\n",
            "\t- Ronald Ketjijere - 8\n",
            "\t- Rudolf Bester - 8\n",
            "\t- Ruth Ndulu Maingi - 8\n",
            "\t- Ruth Negga - 8\n",
            "\t- Ryan Nyambe - 8\n",
            "\t- Saed Benrahma - 8\n",
            "\t- Sahle Work Zewde - 8\n",
            "\t- Saladin Said - 8\n",
            "\t- Salah Aougrout - 8\n",
            "\t- Salma Mumin - 8\n",
            "\t- Sam Mangwana - 8\n",
            "\t- Sam Morsy - 8\n",
            "\t- Sami Dan - 8\n",
            "\t- Samih  Sawiris - 8\n",
            "\t- Samir Guemriche - 8\n",
            "\t- Samuel Bastien - 8\n",
            "\t- Samuel Kuffour - 8\n",
            "\t- Sanaipei Tande - 8\n",
            "\t- Sarah Maldoror - 8\n",
            "\t- Sarkodie - 8\n",
            "\t- Sauti Sol - 8\n",
            "\t- Sebhat Nega - 8\n",
            "\t- Senait Ashenafi - 8\n",
            "\t- Senait Ghebrehiwet Mehari - 8\n",
            "\t- Seyoum Mesfin - 8\n",
            "\t- Shafik Gabr - 8\n",
            "\t- Shatta Wale - 8\n",
            "\t- Shewit Mezgebo - 8\n",
            "\t- Shiloh Jolie-Pitt - 8\n",
            "\t- Shirine Boutella - 8\n",
            "\t- Sindika Dokolo - 8\n",
            "\t- Slyva Mirabel - 8\n",
            "\t- Smith Asante - 8\n",
            "\t- Sofia Boutella - 8\n",
            "\t- Steve Biko - 8\n",
            "\t- Steve Hofmeyr - 8\n",
            "\t- Sulley Muntari - 8\n",
            "\t- Suzanna Owoyo - 8\n",
            "\t- Tabu Ley Rochereau - 8\n",
            "\t- Tagne - 8\n",
            "\t- Tangeni Shipahu - 8\n",
            "\t- Tarek Hamed - 8\n",
            "\t- Tashitaa Tufaa - 8\n",
            "\t- Thabo Mbeki - 8\n",
            "\t- Theodros Teshome - 8\n",
            "\t- Thomas Partey - 8\n",
            "\t- Tiiwtiiw - 8\n",
            "\t- Tinubu - 8\n",
            "\t- Tippi - 8\n",
            "\t- Toke Makinwa - 8\n",
            "\t- Tokyo Sexwale - 8\n",
            "\t- Tolulope Akinyombo - 6\n",
            "\t- Tony Gatlif - 8\n",
            "\t- Tony Leon - 8\n",
            "\t- Tony Yeboah - 8\n",
            "\t- Trevor Manuel - 8\n",
            "\t- Trezeguet - 8\n",
            "\t- Uhuru Kenyatta - 8\n",
            "\t- Victor Wanyama - 8\n",
            "\t- Virgil Vries - 8\n",
            "\t- Vivalda Dula - 8\n",
            "\t- Wahu - 8\n",
            "\t- Walter Sisulu - 8\n",
            "\t- Wangari Maathai - 8\n",
            "\t- Wendo Musaly - 8\n",
            "\t- Wendy Shay - 8\n",
            "\t- Willem Mwedihanga - 8\n",
            "\t- William Samoei Ruto - 8\n",
            "\t- Willy Stephanus - 8\n",
            "\t- Wiyaala - 8\n",
            "\t- Wole Soyinka - 8\n",
            "\t- Yamba Asha - 8\n",
            "\t- Yannick Bolasie - 8\n",
            "\t- Yasmin Said - 8\n",
            "\t- Yasmine Niazy - 8\n",
            "\t- Yasseen Mansour - 8\n",
            "\t- Yasser Ibrahim - 8\n",
            "\t- Yola Semedo - 8\n",
            "\t- Youcef Atal - 8\n",
            "\t- Youlou Mabiala - 8\n",
            "\t- Youssef Mansour - 8\n",
            "\t- Yvonne Chaka Chaka - 8\n",
            "\t- Yvonne Nelson - 7\n",
            "\t- Zahara Marley Jolie-Pitt - 8\n",
            "\t- Zahia Dehar - 8\n",
            "\t- Zainab Balogun - 8\n",
            "\t- Zandre Campos - 8\n",
            "\t- Zeritu Kebede - 8\n",
            "\t- Zito Luvumbo - 8\n",
            "\t- Zizi Adel - 8\n",
            "\t- Zola Matumona - 1\n",
            "Train files\n",
            "\tpath: /content/drive/My Drive/modelos/data/teste\n",
            "\ttotal number: 1000\n",
            "\t- Abah Festus - 2\n",
            "\t- Abay Tsehaye - 2\n",
            "\t- Abdelaziz Bouteflika - 2\n",
            "\t- Abdelaziz Djerad - 2\n",
            "\t- Abdelmadjid Tebboune - 2\n",
            "\t- Abebaw butako - 2\n",
            "\t- Abedi Pele - 2\n",
            "\t- Abel Edime - 2\n",
            "\t- Abosede Olajide - 2\n",
            "\t- Abubeker Nassir - 2\n",
            "\t- Abuya Solomon - 2\n",
            "\t- Adam Bombolb - 2\n",
            "\t- Adam Ounas - 2\n",
            "\t- Adane Girma - 2\n",
            "\t- Adebimpe Olarewaju - 2\n",
            "\t- Adedini Adeola - 2\n",
            "\t- Adegoke Akinyele - 2\n",
            "\t- Adegoke Olamide - 2\n",
            "\t- Adem Zorgane - 2\n",
            "\t- Adesua Etomi - 2\n",
            "\t- Adigun Pelumi - 2\n",
            "\t- Agostinho Kapaia - 2\n",
            "\t- Ahmed Ben Bella - 2\n",
            "\t- Ahmed Elmohamady - 2\n",
            "\t- Ahmed Hegazi - 2\n",
            "\t- Ahmed Kathrada - 2\n",
            "\t- Ahmed Magdy - 2\n",
            "\t- Ahmed Mahgoub - 2\n",
            "\t- Ahmed Mazouz - 2\n",
            "\t- Ahmed Sayed - 2\n",
            "\t- Ahmed saad - 2\n",
            "\t- Ajewole Fasanmi Richard - 2\n",
            "\t- Ajewole Olaitan - 2\n",
            "\t- Akua Dansua - 2\n",
            "\t- Akwa - 2\n",
            "\t- Aladeokin A. Abiodun - 2\n",
            "\t- Albert Luthuli - 2\n",
            "\t- Alemu Aga - 2\n",
            "\t- Alula Girma - 2\n",
            "\t- Amin Askar - 2\n",
            "\t- AminB - 2\n",
            "\t- Amira Selim - 2\n",
            "\t- Amos Wako - 2\n",
            "\t- Amr Waked - 2\n",
            "\t- Andre Ayew - 2\n",
            "\t- Andre Gaspar Mendes de Carvalho - 2\n",
            "\t- Anifowose Mariam - 2\n",
            "\t- Anoushka - 2\n",
            "\t- Anssa Mandi - 2\n",
            "\t- Antanio Mendona - 2\n",
            "\t- Antjie Krog - 2\n",
            "\t- Anton Rupert - 2\n",
            "\t- Anuoluwapo Comfort Kolawole - 2\n",
            "\t- Aristote Nsiala - 2\n",
            "\t- Arlindo Barbeitos - 2\n",
            "\t- Arthur Masuaku - 2\n",
            "\t- Ary Papel - 2\n",
            "\t- Asamoah Gyan - 2\n",
            "\t- Aster Aweke - 2\n",
            "\t- Avril - 2\n",
            "\t- Babatunde Oladogba - 2\n",
            "\t- Basetsana Kumalo - 2\n",
            "\t- Becca - 2\n",
            "\t- Behailu Assefa - 2\n",
            "\t- Behati Prinsloo - 2\n",
            "\t- Bela - 2\n",
            "\t- Ben Malango - 2\n",
            "\t- Ben Ulenga - 2\n",
            "\t- Ben Youcef - 2\n",
            "\t- Benjamin Hauwanga - 2\n",
            "\t- Benjamin Ochieng - 2\n",
            "\t- Benson Shilongo - 2\n",
            "\t- Berhane Gebrekiristos - 2\n",
            "\t- Bertrand Bisimwa - 2\n",
            "\t- Bethlehem Tilahun Alemu - 2\n",
            "\t- Beverly Naya - 2\n",
            "\t- Beyers Naude - 2\n",
            "\t- Bience Gawanas - 2\n",
            "\t- Bill Asamoah - 2\n",
            "\t- Bill Sellanga - 2\n",
            "\t- Birtukan Mideksa - 2\n",
            "\t- Bishop David Abioye - 2\n",
            "\t- Bishop David Oyedepo - 2\n",
            "\t- Black Sherif - 2\n",
            "\t- Bodunha - 2\n",
            "\t- Bonginkosi Dlamini - 2\n",
            "\t- Bozi Boziana - 2\n",
            "\t- Branca Manuel Espirito Santo - 2\n",
            "\t- Brenda Fassie - 2\n",
            "\t- Brenda Wairimu - 2\n",
            "\t- Britier - 2\n",
            "\t- Buhari - 2\n",
            "\t- C. Manuel Cafumana - 2\n",
            "\t- Carlos Conceicao - 2\n",
            "\t- Carmen Suleiman - 2\n",
            "\t- Carolina Cerqueira - 2\n",
            "\t- Catherine Kamau - 2\n",
            "\t- Cedric Bakambu - 2\n",
            "\t- Celso Roberto - 2\n",
            "\t- Chadli Bendjedid - 2\n",
            "\t- Chahrazad Kracheni - 2\n",
            "\t- Chancel Mbemba Mangulu - 2\n",
            "\t- Chara - 2\n",
            "\t- Charlize Theron - 2\n",
            "\t- Cheb Hamidou - 2\n",
            "\t- Cheb Rami - 2\n",
            "\t- Cheb Reda Diamond - 2\n",
            "\t- Chinua Achebe - 2\n",
            "\t- Chris Attoh - 2\n",
            "\t- Chris Hani - 2\n",
            "\t- Chris Kirubi - 2\n",
            "\t- Christabel Ekeh - 2\n",
            "\t- Christian Atsu - 2\n",
            "\t- Christian Luyindama - 2\n",
            "\t- Christian Malanga - 2\n",
            "\t- Christianah Oyewale - 2\n",
            "\t- Christine Wawira - 2\n",
            "\t- Claude Wilfrid Etoka - 2\n",
            "\t- Clemens Kapuuo - 2\n",
            "\t- Collin Benjamin - 2\n",
            "\t- Coussoud-Mavoungou - 2\n",
            "\t- Cyril Ramaphosa - 2\n",
            "\t- Dadju - 2\n",
            "\t- Damilola - 2\n",
            "\t- Damilola Orimolade - 2\n",
            "\t- Daniel Amartey - 2\n",
            "\t- Daniel Aselo Okito - 2\n",
            "\t- Daniel Francois Malan - 2\n",
            "\t- Daniel McKorley - 2\n",
            "\t- Daniel arap Moi - 2\n",
            "\t- Danny Jordaan - 2\n",
            "\t- David Ndjavera - 2\n",
            "\t- Degu Debebe - 2\n",
            "\t- Demeke Mekonnen - 2\n",
            "\t- Denzil Haoseb - 2\n",
            "\t- Deon Kavendji - 2\n",
            "\t- Desmond Tutu - 2\n",
            "\t- Didi Stone Olomide - 2\n",
            "\t- Dieudonne Ndinga Moukala - 2\n",
            "\t- Djalma Campos - 2\n",
            "\t- Don Jazzy - 2\n",
            "\t- Dullah Omar - 2\n",
            "\t- Eddie Kadi - 2\n",
            "\t- Eddie Nartey - 2\n",
            "\t- Edi Gathegi - 2\n",
            "\t- Egas Cacintura - 2\n",
            "\t- Elijah Lagat - 2\n",
            "\t- Elijah Ngurare - 2\n",
            "\t- Elizabeth Ohene - 2\n",
            "\t- Elizabeth Teissier - 2\n",
            "\t- Ephrem Amare - 2\n",
            "\t- Eric Wainaina - 2\n",
            "\t- Erica Chissapa - 2\n",
            "\t- Ermias Amelga - 2\n",
            "\t- Eshele Botende - 2\n",
            "\t- Eslin Kamuhanga - 2\n",
            "\t- Essam El-Hadary - 2\n",
            "\t- Eugkne Terre Blanche - 2\n",
            "\t- Evoloko Jocker - 2\n",
            "\t- Ewatomi - 2\n",
            "\t- Ezenwo Nyesom Wike - 2\n",
            "\t- F. W. de Klerk - 2\n",
            "\t- Fatima Meer - 2\n",
            "\t- Felix Afena-Gyan - 2\n",
            "\t- Femi - 2\n",
            "\t- Fethi Manar - 2\n",
            "\t- Fikru Teferra - 2\n",
            "\t- Flavo Amado - 2\n",
            "\t- Frank Acheampong - 2\n",
            "\t- Frank Artus - 2\n",
            "\t- Frankie Fredericks - 2\n",
            "\t- Fredy - 2\n",
            "\t- Fuad Ibrahim - 2\n",
            "\t- GaNl Kakuta - 2\n",
            "\t- Gary Player - 2\n",
            "\t- Gatoch Panom - 2\n",
            "\t- Gedeon Kalulu - 2\n",
            "\t- Gelila Bekele - 2\n",
            "\t- Gelson Dala - 2\n",
            "\t- Getaneh Kebede - 2\n",
            "\t- Gideon Mensah - 2\n",
            "\t- Girley Jazama - 2\n",
            "\t- Godwin Obaseki - 2\n",
            "\t- Grace Ogot - 2\n",
            "\t- Guilherme Afonso - 2\n",
            "\t- Hage Geingob - 2\n",
            "\t- Haile Gebrselassie - 2\n",
            "\t- Hamdi Fathi - 2\n",
            "\t- Hanan Tarq - 2\n",
            "\t- Hany Ramzy - 2\n",
            "\t- Happiness - 2\n",
            "\t- Haris Belkebla - 2\n",
            "\t- Harry Simon - 2\n",
            "\t- Hassan Kachach - 2\n",
            "\t- Heino Senekal - 2\n",
            "\t- Helalia Johannes - 2\n",
            "\t- Helder Costa - 2\n",
            "\t- Helen Suzman - 2\n",
            "\t- Hendrik Somaeb - 2\n",
            "\t- Hendrik Verwoerd - 2\n",
            "\t- Hicham Boudaoui - 2\n",
            "\t- Hossam Habib - 2\n",
            "\t- Hossam Hassan - 2\n",
            "\t- Houari Boumediene - 2\n",
            "\t- Hussein El Shahat - 2\n",
            "\t- Imaye Taga - 2\n",
            "\t- Isaac Maria dos Anjos - 2\n",
            "\t- Isabel dos Santos - 2\n",
            "\t- IsmaNl Bennacer - 2\n",
            "\t- J. R. R. Tolkien - 2\n",
            "\t- Jackie Appiah - 2\n",
            "\t- Jackson Muleka - 2\n",
            "\t- James Mwangi - 2\n",
            "\t- Jan du Toit - 2\n",
            "\t- Jawar Mohammed - 2\n",
            "\t- Jean Andeka - 2\n",
            "\t- Jean-Claude Bastos de Morais - 2\n",
            "\t- Jean-Pierre Bemba - 2\n",
            "\t- Jemal Tassew - 2\n",
            "\t- Jessica Beshir - 2\n",
            "\t- Jessy Matador - 2\n",
            "\t- Joao Baptista Borges - 2\n",
            "\t- Joao Lourenco - 2\n",
            "\t- Joaquim David - 2\n",
            "\t- Joe Slovo - 2\n",
            "\t- Joel Haikali - 2\n",
            "\t- Johann Rupert - 2\n",
            "\t- John Atta Mills - 2\n",
            "\t- John Dumelo - 2\n",
            "\t- Johnny Clegg - 2\n",
            "\t- Jomo Kenyatta - 2\n",
            "\t- Jonas Ramalho - 2\n",
            "\t- Jonathan Buatu - 2\n",
            "\t- Jonl Kimwaki - 2\n",
            "\t- Jonty Rhodes - 2\n",
            "\t- Jordan Ayew - 2\n",
            "\t- Jordan Botaka - 2\n",
            "\t- Jose Eduardo dos Santos - 2\n",
            "\t- Joseph Siaw Agyapong - 2\n",
            "\t- Josiah Mwangi Kariuki - 2\n",
            "\t- Josky Kiambukuta - 2\n",
            "\t- Juanita du Plessis - 2\n",
            "\t- Kader Japonais - 2\n",
            "\t- Kahush - 2\n",
            "\t- Kaizer Motaung - 2\n",
            "\t- Kaka Sungura - 2\n",
            "\t- Kali - 2\n",
            "\t- Kamel Belghazi - 2\n",
            "\t- Kamo Mphela - 2\n",
            "\t- Kayode - 2\n",
            "\t- Kehinde - 2\n",
            "\t- Kemi - 2\n",
            "\t- Kevin-Prince Boateng - 2\n",
            "\t- Khaligraph Jones - 2\n",
            "\t- Koigi wa Wamwere - 2\n",
            "\t- Kuami Eugene - 2\n",
            "\t- Kunleola Adebayo - 2\n",
            "\t- Kwadwo Asamoah - 2\n",
            "\t- Kwaku Manu - 2\n",
            "\t- Kwesi Arthur - 2\n",
            "\t- Lakhdar Brahimi - 2\n",
            "\t- Larbi Ben Mhid - 2\n",
            "\t- Lazarus Kaimbi - 2\n",
            "\t- Leon Schuster - 2\n",
            "\t- Liamine Zeroual - 2\n",
            "\t- Liya Kebede - 2\n",
            "\t- Loco - 2\n",
            "\t- Lord Paul Boateng - 2\n",
            "\t- Lucien Ebata - 2\n",
            "\t- Lydia Forson - 2\n",
            "\t- Lyes Salem - 2\n",
            "\t- Lyna Khoudri - 2\n",
            "\t- MBala Nzola - 2\n",
            "\t- Madilu System - 2\n",
            "\t- Mahder Assefa - 2\n",
            "\t- Mahmoud Hamdy - 2\n",
            "\t- Majid Michel - 2\n",
            "\t- Mama Ngina Kenyatta - 2\n",
            "\t- Mandoza - 2\n",
            "\t- Mangosuthu Buthelezi - 2\n",
            "\t- Manucho - 2\n",
            "\t- Marco Airosa - 2\n",
            "\t- Marcus Samuelsson - 2\n",
            "\t- Marie Daulne - 2\n",
            "\t- Mark Shuttleworth - 2\n",
            "\t- Marlice van Vuuren - 2\n",
            "\t- Martha Ankomah - 2\n",
            "\t- Mary Oyaya - 2\n",
            "\t- Mateus Galiano da Costa - 2\n",
            "\t- Mayowa Afolabi - 2\n",
            "\t- Mejja - 2\n",
            "\t- Mekonnen Knife - 2\n",
            "\t- Mercy Myra - 2\n",
            "\t- Merouane Guerouabi - 2\n",
            "\t- Merveille Bokadi - 2\n",
            "\t- Micaela Reis - 2\n",
            "\t- Michael Crichton - 2\n",
            "\t- Michael Essien - 2\n",
            "\t- Michael Kennedy Naiboi - 2\n",
            "\t- Michael Olunga - 2\n",
            "\t- Michelle McLean - 2\n",
            "\t- Mido - 2\n",
            "\t- Mike Ezuruonye - 2\n",
            "\t- Mike Sonko - 2\n",
            "\t- Milson - 2\n",
            "\t- Minyahil Teshome - 2\n",
            "\t- Miriam Makeba - 2\n",
            "\t- Mohamed Abdelmonem - 2\n",
            "\t- Mohamed Aboutrika - 2\n",
            "\t- Mohamed Elneny - 2\n",
            "\t- Mohamed Fares - 2\n",
            "\t- Mohamed Fayed - 2\n",
            "\t- Mohamed Hussein Tantawi - 2\n",
            "\t- Mohamed Laid Benamor - 2\n",
            "\t- Mohamed Magdy - 2\n",
            "\t- Mohamed Mansour - 2\n",
            "\t- Mohamed Salah - 2\n",
            "\t- Mohamed Sherif - 2\n",
            "\t- Mohamed Zidan - 2\n",
            "\t- Mohammed Al Amoudi - 2\n",
            "\t- Mohammed El Shenawy - 2\n",
            "\t- Mohammed Kudus - 2\n",
            "\t- Mohammed Ouseb - 2\n",
            "\t- Mohammed Salisu - 2\n",
            "\t- Moise Katumbi - 2\n",
            "\t- Mose Se Sengo - 2\n",
            "\t- Moses Wetangula - 2\n",
            "\t- Moshe Abebe - 2\n",
            "\t- Mostafa Fathi - 2\n",
            "\t- Mostafa Mohamed - 2\n",
            "\t- Mouni Bouallam - 2\n",
            "\t- Mourad Eulmi - 2\n",
            "\t- Muhammad Boudiaf - 2\n",
            "\t- Muluken Melesse - 2\n",
            "\t- Mustapha Laribi - 2\n",
            "\t- Mwai Kibaki - 2\n",
            "\t- Nader Ghabbour - 2\n",
            "\t- Nader Hamdy - 2\n",
            "\t- Nadia Buari - 2\n",
            "\t- Nadia Mukami - 2\n",
            "\t- Naguib Sawiris - 2\n",
            "\t- Nancy Isime - 2\n",
            "\t- Nancy Johannes - 2\n",
            "\t- Nassef Sawiris - 2\n",
            "\t- Nelson Mandela - 2\n",
            "\t- Nelson da Luz - 2\n",
            "\t- Neway Debebe - 2\n",
            "\t- Nhatty Man - 2\n",
            "\t- Nianell - 2\n",
            "\t- Nicholas Biwott - 2\n",
            "\t- Nick Mutumqa - 2\n",
            "\t- Nicole Garcia - 2\n",
            "\t- Nikita Kering - 2\n",
            "\t- Nixau Toma - 2\n",
            "\t- Nkosazana Dlamini-Zuma - 2\n",
            "\t- Nour El Sayed - 2\n",
            "\t- Nyashinski - 2\n",
            "\t- Obasanjo - 2\n",
            "\t- Okon Abosede Ola - 2\n",
            "\t- Okyeame Kwame - 2\n",
            "\t- Olagbende Ebenezer - 2\n",
            "\t- Olaku Temitope - 2\n",
            "\t- Oliver Litondo - 2\n",
            "\t- Oliver Risser - 2\n",
            "\t- Oliver Tambo - 2\n",
            "\t- Oluwaseyi Makinde - 2\n",
            "\t- Oluwatoyin Olajumoke - 2\n",
            "\t- Omar Marmoush - 2\n",
            "\t- Omenuke Mfulu - 2\n",
            "\t- Omer Ali Shifaw - 2\n",
            "\t- Onsi  Sawiris - 2\n",
            "\t- Oscar Maritu - 2\n",
            "\t- Otile Brown - 2\n",
            "\t- Oumed Oukri - 2\n",
            "\t- Owolabi Rukayat Adeshola - 2\n",
            "\t- Oyinkansola - 2\n",
            "\t- P. W. Botha - 2\n",
            "\t- Papa Wemba - 2\n",
            "\t- Pascal Tokodi - 2\n",
            "\t- Pastor Enoch Adeboye - 2\n",
            "\t- Patrice Motse - 2\n",
            "\t- Patricia de Lille - 2\n",
            "\t- Patsha Bay - 2\n",
            "\t- Paul Kruger - 2\n",
            "\t- Paulao - 2\n",
            "\t- Paulino Baptista - 2\n",
            "\t- Paulus Ambunda - 2\n",
            "\t- Percy Montgomery - 2\n",
            "\t- Peter Shalulile - 2\n",
            "\t- Pieter Dirk Uys - 2\n",
            "\t- Prince David Osei - 2\n",
            "\t- Quinzinho - 2\n",
            "\t- Raila Odinga - 2\n",
            "\t- Ramy Bensebaini - 2\n",
            "\t- Ramy Gamal - 2\n",
            "\t- Ramy Sabry - 2\n",
            "\t- Raouf Ghabbour - 2\n",
            "\t- Raphael Soriano Katoto Katebe - 2\n",
            "\t- Ras Samuel Weldaabzgi - 2\n",
            "\t- Rasselas Lakew - 2\n",
            "\t- Ray Lema - 2\n",
            "\t- Raymond Ofula - 2\n",
            "\t- Razundara - 2\n",
            "\t- Reggie Rockstone - 2\n",
            "\t- Richard Leakey - 2\n",
            "\t- Riyad Mahrez - 2\n",
            "\t- Robert Nauseb - 2\n",
            "\t- Robert Sobukwe - 2\n",
            "\t- Romand - 2\n",
            "\t- Ronald Ketjijere - 2\n",
            "\t- Rudolf Bester - 2\n",
            "\t- Ruth Ndulu Maingi - 2\n",
            "\t- Ruth Negga - 2\n",
            "\t- Ryan Nyambe - 2\n",
            "\t- Saed Benrahma - 2\n",
            "\t- Sahle Work Zewde - 2\n",
            "\t- Saladin Said - 2\n",
            "\t- Salah Aougrout - 2\n",
            "\t- Salma Mumin - 2\n",
            "\t- Sam Mangwana - 2\n",
            "\t- Sam Morsy - 2\n",
            "\t- Sami Dan - 2\n",
            "\t- Samih  Sawiris - 2\n",
            "\t- Samir Guemriche - 2\n",
            "\t- Samuel Bastien - 2\n",
            "\t- Samuel Kuffour - 2\n",
            "\t- Sanaipei Tande - 2\n",
            "\t- Sarah Maldoror - 2\n",
            "\t- Sarkodie - 2\n",
            "\t- Sauti Sol - 2\n",
            "\t- Sebhat Nega - 2\n",
            "\t- Senait Ashenafi - 2\n",
            "\t- Senait Ghebrehiwet Mehari - 2\n",
            "\t- Seyoum Mesfin - 2\n",
            "\t- Shafik Gabr - 2\n",
            "\t- Shatta Wale - 2\n",
            "\t- Shewit Mezgebo - 2\n",
            "\t- Shiloh Jolie-Pitt - 2\n",
            "\t- Shirine Boutella - 2\n",
            "\t- Sindika Dokolo - 2\n",
            "\t- Slyva Mirabel - 2\n",
            "\t- Smith Asante - 2\n",
            "\t- Sofia Boutella - 2\n",
            "\t- Steve Biko - 2\n",
            "\t- Steve Hofmeyr - 2\n",
            "\t- Sulley Muntari - 2\n",
            "\t- Suzanna Owoyo - 2\n",
            "\t- Tabu Ley Rochereau - 2\n",
            "\t- Tagne - 2\n",
            "\t- Tangeni Shipahu - 2\n",
            "\t- Tarek Hamed - 2\n",
            "\t- Tashitaa Tufaa - 2\n",
            "\t- Thabo Mbeki - 2\n",
            "\t- Theodros Teshome - 2\n",
            "\t- Thomas Partey - 2\n",
            "\t- Tiiwtiiw - 2\n",
            "\t- Tinubu - 2\n",
            "\t- Tippi - 2\n",
            "\t- Toke Makinwa - 2\n",
            "\t- Tokyo Sexwale - 2\n",
            "\t- Tolulope Akinyombo - 2\n",
            "\t- Tony Gatlif - 2\n",
            "\t- Tony Leon - 2\n",
            "\t- Tony Yeboah - 2\n",
            "\t- Trevor Manuel - 2\n",
            "\t- Trezeguet - 2\n",
            "\t- Uhuru Kenyatta - 2\n",
            "\t- Victor Wanyama - 2\n",
            "\t- Virgil Vries - 2\n",
            "\t- Vivalda Dula - 2\n",
            "\t- Wahu - 2\n",
            "\t- Walter Sisulu - 2\n",
            "\t- Wangari Maathai - 2\n",
            "\t- Wendo Musaly - 2\n",
            "\t- Wendy Shay - 2\n",
            "\t- Willem Mwedihanga - 2\n",
            "\t- William Samoei Ruto - 2\n",
            "\t- Willy Stephanus - 2\n",
            "\t- Wiyaala - 2\n",
            "\t- Wole Soyinka - 2\n",
            "\t- Yamba Asha - 2\n",
            "\t- Yannick Bolasie - 2\n",
            "\t- Yasmin Said - 2\n",
            "\t- Yasmine Niazy - 2\n",
            "\t- Yasseen Mansour - 2\n",
            "\t- Yasser Ibrahim - 2\n",
            "\t- Yola Semedo - 2\n",
            "\t- Youcef Atal - 2\n",
            "\t- Youlou Mabiala - 2\n",
            "\t- Youssef Mansour - 2\n",
            "\t- Yvonne Chaka Chaka - 2\n",
            "\t- Yvonne Nelson - 2\n",
            "\t- Zahara Marley Jolie-Pitt - 2\n",
            "\t- Zahia Dehar - 2\n",
            "\t- Zainab Balogun - 2\n",
            "\t- Zandre Campos - 2\n",
            "\t- Zeritu Kebede - 2\n",
            "\t- Zito Luvumbo - 2\n",
            "\t- Zizi Adel - 2\n",
            "\t- Zola Matumona - 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf2WT3ubOANw"
      },
      "source": [
        "# 2. Convert all img to RGB\n",
        "to_rgb_and_save(trainF), to_rgb_and_save(testF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJB44d5802TR"
      },
      "source": [
        "**Image plotter fuctions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXtHrHF80rXl"
      },
      "source": [
        "from math import ceil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "%matplotlib inline\n",
        "\n",
        "from matplotlib.patches import Ellipse\n",
        "\n",
        "\n",
        "def imshow(img, ax, title):\n",
        "    ax.imshow(img)\n",
        "    if title:\n",
        "        el = Ellipse((2, -1), 0.5, 0.5)\n",
        "        ax.annotate(title, xy=(1, 0), xycoords='axes fraction', ha='right', va='bottom',\n",
        "                    bbox=dict(boxstyle=\"round\", fc=\"0.8\"),\n",
        "                    arrowprops=dict(arrowstyle=\"simple\", fc=\"0.6\", ec=\"none\",\n",
        "                                    patchB=el, connectionstyle=\"arc3, rad=0.3\"))\n",
        "    ax.set_xticks([]), ax.set_yticks([])\n",
        "\n",
        "def plot_gallery(images, ncols, nrows, titles=None, title='', figsize=None):\n",
        "    if figsize is None:\n",
        "        figsize = (18, ncols) if ncols < 10 else (18, 20)\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    grid = ImageGrid(fig, 111, nrows_ncols=(nrows, ncols), axes_pad=0.02)\n",
        "\n",
        "    for i, ax in enumerate(grid):\n",
        "        if i == len(images): break\n",
        "        imshow(images[i], ax, titles[i] if titles is not None else '')\n",
        "\n",
        "    # there are some problems with suptitle alignment\n",
        "    y_title_pos = grid[0].get_position().get_points()[1][1] - 0.33 / (1 if nrows == 1 else nrows / 3)\n",
        "    plt.suptitle(title, y=y_title_pos, fontsize=12)\n",
        "\n",
        "def plot(paths=None, images=None, titles=None, axtitle=True, title='', to_size=(512, 512)):\n",
        "    \"\"\"\n",
        "    Plot image gallery by passing (paths, title) or (images, titles)\n",
        "    :param paths: list of image paths\n",
        "    :param images: list of (PIL.Image | np.array | torch.Tensor) objects\n",
        "    :param titles: list of image titles\n",
        "    :param bool axtitle: if paths is not None, then axtitle=True leads to use basedir name as titles\n",
        "    :param str title: gallery title\n",
        "    :param to_size: image resizing size before plot, default (512, 512)\n",
        "    \"\"\"\n",
        "\n",
        "    if paths is not None and len(paths):\n",
        "        images = [Image.open(p).resize(to_size) for p in paths]\n",
        "\n",
        "        nrows = int(ceil(len(images) / 12)) # 12 images per row\n",
        "        ncols = 12 if nrows > 1 else len(images)\n",
        "\n",
        "        if axtitle:\n",
        "              titles = [os.path.dirname(p).split('/')[-1] for p in paths]\n",
        "\n",
        "        plot_gallery(images, ncols, nrows, titles, title)\n",
        "\n",
        "    elif images is not None and len(images):\n",
        "        if isinstance(images, list):\n",
        "            images = np.array(images)\n",
        "\n",
        "        nrows = int(ceil(len(images) / 12)) # 12 images per row\n",
        "        ncols = 12 if nrows > 1 else len(images)\n",
        "\n",
        "        # Rescale to [0., 1.]\n",
        "        if images[0].max() > 1:\n",
        "            images /= 255.\n",
        "\n",
        "        # if torch.Tensor change axes\n",
        "        if not isinstance(images, np.ndarray):\n",
        "            if images.size(1) == 3 or 1:\n",
        "                images = images.permute((0, 2, 3, 1))\n",
        "\n",
        "        plot_gallery(images, ncols, nrows, titles, title)\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise LookupError('You didnt pass any path or image objects')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh0AbAtHwDC6"
      },
      "source": [
        "plot(paths=trainF, title='Train images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvb78oCKZjBc"
      },
      "source": [
        "plot(paths=testF, title='Test images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9ZoaZ_y95zc"
      },
      "source": [
        "**Install facenet_pytorch with MTCNN detection and pretrained vggface-2 InceptionResnetV1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qci3jkvT94s9"
      },
      "source": [
        "# !pip install facenet-pytorch\n",
        "\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1, training, fixed_image_standardization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG78gab01ALj"
      },
      "source": [
        "**Function for cropping and saving images based on MTCNN detector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q_vAM0sN_74"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import shutil\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Running on device: {device}')\n",
        "\n",
        "\n",
        "def crop_face_and_save(path, new_path=None, model=MTCNN, transformer=None, params=None):\n",
        "    \"\"\"\n",
        "    Detect face on each image, crop them and save to \"new_path\"\n",
        "    :param str path: path with images will be passed to  datasets.ImageFolder\n",
        "    :param str new_path: path to locate new \"aligned\" images, if new_path is None\n",
        "                     then new_path will be path + \"_cropped\"\n",
        "    :param model: model to detect faces, default MTCNN\n",
        "    :param transformer: transformer object will be passed to ImageFolder\n",
        "    :param params: parameters of MTCNN model\n",
        "    \"\"\"\n",
        "    if not new_path:\n",
        "        new_path = path + '_cropped'\n",
        "\n",
        "    # in case new_path exists MTCNN model will raise error\n",
        "    if os.path.exists(new_path):\n",
        "        shutil.rmtree(new_path)\n",
        "\n",
        "    # it is default parameters for MTCNN\n",
        "    if not params:\n",
        "        params = {\n",
        "            'image_size': 160, 'margin': 0,\n",
        "            'min_face_size': 10, 'thresholds': [0.6, 0.7, 0.7],\n",
        "            'factor': 0.709, 'post_process': False, 'device': device\n",
        "            }\n",
        "\n",
        "    model = model(**params)\n",
        "\n",
        "    if not transformer:\n",
        "        transformer = transforms.Lambda(\n",
        "            lambd=lambda x: x.resize((1280, 1280)) if (np.array(x) > 2000).all() else x\n",
        "        )\n",
        "    # for convenience we will use ImageFolder instead of getting Image objects by file paths\n",
        "    dataset = datasets.ImageFolder(path, transform=transformer)\n",
        "    dataset.samples = [(p, p.replace(path, new_path)) for p, _ in dataset.samples]\n",
        "\n",
        "    # batch size 1 as long as we havent exact image size and MTCNN will raise an error\n",
        "    loader = DataLoader(dataset, batch_size=1, collate_fn=training.collate_pil)\n",
        "    for i, (x, y) in enumerate(tqdm.tqdm(loader)):\n",
        "        model(x, save_path=y)\n",
        "\n",
        "    # spare some memory\n",
        "    del model, loader, dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bDrYCGP09dP"
      },
      "source": [
        "**Detect/Crop faces and save \"new\" aligned images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsAMOMvnN_u_"
      },
      "source": [
        "# 3. Crop train dataset faces and save aligned images\n",
        "print('\\t- Train data')\n",
        "crop_face_and_save(TRAIN_DIR, ALIGNED_TRAIN_DIR)\n",
        "\n",
        "detect_failed_train_files = []\n",
        "\n",
        "# check if some imgs were missed by detector and failed to save\n",
        "train_files, train_aligned_files = get_files(TRAIN_DIR), get_files(ALIGNED_TRAIN_DIR)\n",
        "if len(train_files) != len(train_aligned_files):\n",
        "    files = set(map(lambda fp: os.path.relpath(fp, start=TRAIN_DIR), train_files))\n",
        "    aligned_files = set(map(lambda fp: os.path.relpath(fp, start=ALIGNED_TRAIN_DIR), train_aligned_files))\n",
        "    detect_failed_train_files = list(files - aligned_files)\n",
        "    print(f\"\\nfiles {len(aligned_files)}/{len(files)}: {', '.join(detect_failed_train_files)} were not saved\")\n",
        "\n",
        "# -------------                     -------------\n",
        "\n",
        "# Crop test dataset faces and save aligned images\n",
        "print('\\t- Test data')\n",
        "crop_face_and_save(TEST_DIR, ALIGNED_TEST_DIR)\n",
        "\n",
        "# check if some imgs were missed by detector and failed to save\n",
        "test_files, test_aligned_files = get_files(TEST_DIR), get_files(ALIGNED_TEST_DIR)\n",
        "if len(test_files) != len(test_aligned_files):\n",
        "    files = set(map(lambda fp: os.path.relpath(fp, start=TEST_DIR), test_files))\n",
        "    aligned_files = set(map(lambda fp: os.path.relpath(fp, start=ALIGNED_TEST_DIR), test_aligned_files))\n",
        "    detect_failed_test_files = list(files - aligned_files)\n",
        "    print(f\"\\nfiles {len(aligned_files)}/{len(files)}: {', '.join(detect_failed_train_files)} were not saved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtIBvkiOZ3m1"
      },
      "source": [
        "trainF = get_files(ALIGNED_TRAIN_DIR)\n",
        "plot(paths=trainF, title='Aligned train images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QQgXn1SZ6p8"
      },
      "source": [
        "testF = get_files(ALIGNED_TEST_DIR)\n",
        "plot(paths=testF, title='Aligned test images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzBzx4eZaCLw"
      },
      "source": [
        "# Plot failed to aligned train images\n",
        "trainFailF = list(map(lambda fp: os.path.join(TRAIN_DIR, fp), detect_failed_train_files))\n",
        "\n",
        "if trainFailF:  # Verifique se há imagens para plotar\n",
        "    plot(paths=trainFailF)\n",
        "else:\n",
        "    print(\"Nenhuma imagem falhou no alinhamento, nada a plotar.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9hmwqfMGogD"
      },
      "source": [
        "**Install albumentations for augmentations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7x67ph6GiGq"
      },
      "source": [
        "# !pip install albumentations\n",
        "\n",
        "import albumentations as A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_3rbM-KG2Nv"
      },
      "source": [
        "**Transformer for data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vZf4a3d4Nr1"
      },
      "source": [
        "from facenet_pytorch import fixed_image_standardization\n",
        "\n",
        "standard_transform = transforms.Compose([\n",
        "                                np.float32,\n",
        "                                transforms.ToTensor(),\n",
        "                                fixed_image_standardization\n",
        "])\n",
        "\n",
        "aug_mask = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.15),\n",
        "    A.RandomBrightnessContrast(contrast_limit=0.5, brightness_limit=0.2, p=0.4),\n",
        "    A.Rotate(30, p=0.2),\n",
        "    A.RandomSizedCrop((120, 120), 160, 160, p=0.4),\n",
        "    A.OneOrOther(A.ImageCompression(p=0.2), A.Blur(p=0.2), p=0.66),\n",
        "    A.OneOf([\n",
        "        A.Rotate(45, p=0.3),\n",
        "        A.ElasticTransform(sigma=20, alpha_affine=None, border_mode=0, p=0.2)  # alpha_affine definido como None\n",
        "    ], p=0.5),\n",
        "    A.HueSaturationValue(val_shift_limit=10, p=0.3)\n",
        "], p=1)\n",
        "\n",
        "\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "                                 transforms.Lambda(lambd=lambda x: aug_mask(image=np.array(x))['image']),\n",
        "                                 standard_transform\n",
        "    ]),\n",
        "    'test': standard_transform\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0OpgmMZKmnf"
      },
      "source": [
        "**DataLoader for train/test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDeMxXJ0PhMF"
      },
      "source": [
        "from torch.utils.data import SubsetRandomSampler\n",
        "\n",
        "\n",
        "b = 32\n",
        "\n",
        "# Original train images\n",
        "trainD = datasets.ImageFolder(ALIGNED_TRAIN_DIR, transform=standard_transform)\n",
        "# Augmented train images\n",
        "trainD_aug = datasets.ImageFolder(ALIGNED_TRAIN_DIR, transform=transform['train'])\n",
        "# Train Loader\n",
        "trainL = DataLoader(trainD, batch_size=b, num_workers=2) # x: torch.Size([batch_size, 3, 160, 160]), y: torch.Size([batch_size])\n",
        "trainL_aug = DataLoader(trainD_aug, batch_size=b, num_workers=2)\n",
        "\n",
        "# Original test images\n",
        "testD = datasets.ImageFolder(ALIGNED_TEST_DIR, transform=standard_transform)\n",
        "# Test Loader\n",
        "testL = DataLoader(testD, batch_size=b, num_workers=2)\n",
        "\n",
        "# Convert encoded labels to named claasses\n",
        "IDX_TO_CLASS = np.array(list(trainD.class_to_idx.keys()))\n",
        "CLASS_TO_IDX = dict(trainD.class_to_idx.items())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIEuTbOuNaQ5"
      },
      "source": [
        "**Prepare model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvjDBZk_NdLC"
      },
      "source": [
        "from facenet_pytorch import InceptionResnetV1\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2', dropout_prob=0.5, device=device).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EJgRLGvL5QU"
      },
      "source": [
        "**Function for embedding extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-nRsJLKM81M"
      },
      "source": [
        "def fixed_denormalize(image):\n",
        "    \"\"\" Restandartize images to [0, 255]\"\"\"\n",
        "    return image * 128 + 127.5\n",
        "\n",
        "def getEmbeds(model, n, loader, imshow=False, n_img=5):\n",
        "    model.eval()\n",
        "    # images to display\n",
        "    images = []\n",
        "\n",
        "    embeds, labels = [], []\n",
        "    for n_i in tqdm.trange(n):\n",
        "        for i, (x, y) in enumerate(loader, 1):\n",
        "\n",
        "            # on each first batch get 'n_img' images\n",
        "            if imshow and i == 1:\n",
        "                inds = np.random.choice(x.size(0), min(x.size(0), n_img))\n",
        "                images.append(fixed_denormalize(x[inds].data.cpu()).permute((0, 2, 3, 1)).numpy())\n",
        "\n",
        "            embed = model(x.to(device))\n",
        "            embed = embed.data.cpu().numpy()\n",
        "            embeds.append(embed), labels.extend(y.data.cpu().numpy())\n",
        "\n",
        "    if imshow:\n",
        "        plot(images=np.concatenate(images))\n",
        "\n",
        "    return np.concatenate(embeds), np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B95ZRkfbR1-G"
      },
      "source": [
        "**Extract embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Pi4jL5X9kZ"
      },
      "source": [
        "# 3. Get embeddings\n",
        "# Train embeddings\n",
        "trainEmbeds, trainLabels = getEmbeds(model, 1, trainL, False)\n",
        "trainEmbeds_aug, trainLabels_aug = getEmbeds(model, 50, trainL_aug, imshow=True, n_img=3)\n",
        "\n",
        "trainEmbeds = np.concatenate([trainEmbeds, trainEmbeds_aug])\n",
        "trainLabels = np.concatenate([trainLabels, trainLabels_aug])\n",
        "\n",
        "# Test embeddings\n",
        "testEmbeds, testLabels = getEmbeds(model, 1, testL, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAZk_3Xsa5jL"
      },
      "source": [
        "# 4. Save embeddings\n",
        "TRAIN_EMBEDS = os.path.join(DATA_PATH, 'trainEmbeds.npz')\n",
        "TEST_EMBEDS = os.path.join(DATA_PATH, 'testEmbeds.npz')\n",
        "\n",
        "np.savez(TRAIN_EMBEDS, x=trainEmbeds, y=trainLabels)\n",
        "np.savez(TEST_EMBEDS, x=testEmbeds, y=testLabels)\n",
        "\n",
        "# Load the saved embeddings to use them futher\n",
        "trainEmbeds, trainLabels = np.load(TRAIN_EMBEDS, allow_pickle=True).values()\n",
        "testEmbeds, testLabels = np.load(TEST_EMBEDS, allow_pickle=True).values()\n",
        "\n",
        "# Get named labels\n",
        "trainLabels, testLabels = IDX_TO_CLASS[trainLabels], IDX_TO_CLASS[testLabels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-R0sBZlXPqt"
      },
      "source": [
        "**Function for embedding calculations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHqwdeJ_4N-m"
      },
      "source": [
        "from sklearn.metrics import pairwise_distances\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "def getDist(x, metric='euclidean', index=None, columns=None):\n",
        "    dists = pairwise_distances(x, x, metric=metric)\n",
        "    return pd.DataFrame(dists, index=index, columns=columns)\n",
        "\n",
        "def heatmap(x, title='', cmap='Greens', linewidth=1):\n",
        "    plt.figure(figsize=(17, 12))\n",
        "    plt.title(title)\n",
        "    sns.heatmap(x, cmap=cmap, square=True)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOh9PB7-c-ot"
      },
      "source": [
        "**Get distance matrix for each image embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt7zLvHbeHb4"
      },
      "source": [
        "num_originals = min(88, len(trainEmbeds))  # Garante que não ultrapassamos o tamanho real de trainEmbeds\n",
        "inds = range(num_originals)\n",
        "\n",
        "# Calcular distâncias usando apenas os índices válidos\n",
        "# Embeddings de treino - distância euclidiana\n",
        "dists = getDist(trainEmbeds[inds], metric='euclidean', index=trainLabels[inds], columns=trainLabels[inds])\n",
        "heatmap(dists, 'euclidean distance')\n",
        "\n",
        "# Embeddings de treino - distância de cosseno\n",
        "dists = getDist(trainEmbeds[inds], metric='cosine', index=trainLabels[inds], columns=trainLabels[inds])\n",
        "heatmap(dists, 'cosine distance')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3enjpCqRSC6a"
      },
      "source": [
        "# Test embeddings\n",
        "dists = getDist(testEmbeds, metric='euclidean', index=testLabels, columns=testLabels)\n",
        "heatmap(dists, 'euclidean distance')\n",
        "\n",
        "dists = getDist(testEmbeds, metric='cosine', index=testLabels, columns=testLabels)\n",
        "heatmap(dists, 'cosine distance')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjR2STiBnChj"
      },
      "source": [
        "**Take a look at how TSNE & PCA methods clustered our images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WAuRmSGRamb"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "# Determine o número de amostras disponíveis\n",
        "num_train_samples = min(88, len(trainEmbeds))  # Use o menor valor entre 88 e o tamanho de trainEmbeds\n",
        "inds = range(num_train_samples)  # Atualize o intervalo de índices\n",
        "\n",
        "# Agora use o índice atualizado para t-SNE\n",
        "X_tsne1 = TSNE(n_components=2, init='pca', random_state=33).fit_transform(trainEmbeds[inds])\n",
        "X_tsne2 = TSNE(n_components=2, init='random', random_state=33).fit_transform(trainEmbeds[inds])\n",
        "y = [CLASS_TO_IDX[label] for label in trainLabels[inds]]\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 8))\n",
        "\n",
        "img = ax[0].scatter(X_tsne1[:, 0], X_tsne1[:, 1], c=y, alpha=0.5, cmap=plt.cm.get_cmap('nipy_spectral', 10))\n",
        "ax[1].scatter(X_tsne2[:, 0], X_tsne2[:, 1], c=y, alpha=0.5, cmap=plt.cm.get_cmap('nipy_spectral', 10))\n",
        "\n",
        "ax[0].set_title('TSNE with pca init')\n",
        "ax[1].set_title('TSNE with random init')\n",
        "plt.suptitle('Face embeddings')\n",
        "\n",
        "cbar = plt.colorbar(img, ax=ax)\n",
        "cbar.ax.set_yticklabels(np.unique(trainLabels[inds]))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QQgvEV9fdnY"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Obtenha o número de amostras\n",
        "n_samples = trainEmbeds.shape[0]  # Total de amostras em trainEmbeds\n",
        "\n",
        "# Use o número de amostras para definir o intervalo, garantindo que não ultrapasse\n",
        "inds = range(min(88, n_samples))  # Garante que não ultrapasse o tamanho\n",
        "\n",
        "# PCA\n",
        "X_pca1 = PCA(n_components=2, random_state=33).fit_transform(trainEmbeds[inds])\n",
        "y = [CLASS_TO_IDX[label] for label in trainLabels[inds]]\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "img = ax.scatter(X_pca1[:, 0], X_pca1[:, 1], c=y, alpha=0.5, cmap=plt.cm.get_cmap('nipy_spectral', 10))\n",
        "\n",
        "plt.title('PCA method')\n",
        "plt.suptitle('Face embeddings')\n",
        "\n",
        "cbar = plt.colorbar(img, ax=ax)\n",
        "cbar.ax.set_yticklabels(np.unique(trainLabels[inds]))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1hlJGrSsDyh"
      },
      "source": [
        "**Find optimal parameters for SVC classifier and train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZXltW5IoZiZ"
      },
      "source": [
        "# data preparation\n",
        "X = np.copy(trainEmbeds)\n",
        "y = np.array([CLASS_TO_IDX[label] for label in trainLabels])\n",
        "\n",
        "print(f'X train embeds size: {X.shape}')\n",
        "print(f'Tagret train size: {y.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_USfruFsoI6"
      },
      "source": [
        "**As we see, in order to find optimal parameters among ```'param_grid'``` the whole search process took ~ 1.5 hours**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpByRDQ2rLda"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore', 'Solver terminated early.*')\n",
        "\n",
        "# Preparação dos dados\n",
        "X = np.copy(trainEmbeds)  # Supondo que trainEmbeds esteja definido no arquivo principal\n",
        "y = np.array([CLASS_TO_IDX[label] for label in trainLabels])  # Supondo que CLASS_TO_IDX e trainLabels estejam definidos\n",
        "\n",
        "# Verificação das classes\n",
        "unique_classes = np.unique(y)\n",
        "print(\"Classes únicas em y:\", unique_classes)\n",
        "print(\"Número de classes:\", len(unique_classes))\n",
        "\n",
        "if len(unique_classes) <= 1:\n",
        "    raise ValueError(\"O conjunto de dados deve conter mais de uma classe para treinar o modelo.\")\n",
        "\n",
        "# Espaço de hiperparâmetros com mais opções para aumentar a precisão\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100, 1000],  # Ampliado para incluir valores menores\n",
        "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],  # Ampliado para incluir valores maiores\n",
        "    'kernel': ['linear', 'rbf']  # Incluído 'linear' para testar outro tipo de kernel\n",
        "}\n",
        "\n",
        "# Parâmetros adicionais do modelo SVM\n",
        "model_params = {'class_weight': 'balanced', 'probability': True, 'random_state': 3}\n",
        "\n",
        "# Criando o modelo SVC\n",
        "model = SVC(**model_params)\n",
        "\n",
        "# Busca exaustiva com GridSearchCV\n",
        "clf = GridSearchCV(model, param_grid, cv=5, verbose=3, n_jobs=-1)  # 'cv=5' para validação cruzada, 'n_jobs=-1' usa todos os núcleos disponíveis\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Resultados\n",
        "print('Melhor estimador: ', clf.best_estimator_)\n",
        "print('Melhores parâmetros: ', clf.best_params_)\n",
        "print('Acurácia com os melhores parâmetros: {:.2f}%'.format(clf.best_score_ * 100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxFLzAG3uqj7"
      },
      "source": [
        "**Load & save SVC model, basically weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADvLChrkpHNV"
      },
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "# Definir o caminho para salvar o modelo SVM\n",
        "SVM_PATH = os.path.join(DATA_PATH, 'svm.sav')\n",
        "\n",
        "# Verificar se o modelo já existe. Se não existir, treina e salva o modelo.\n",
        "if os.path.exists(SVM_PATH):\n",
        "    print(\"Carregando o modelo salvo.\")\n",
        "    clf = joblib.load(SVM_PATH)\n",
        "else:\n",
        "    print(\"Modelo não encontrado. Treinando e salvando o modelo.\")\n",
        "\n",
        "    # Parâmetros do SVM e do GridSearch\n",
        "    param_grid = {'C': [1, 10, 100, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
        "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 'auto'],\n",
        "                  'kernel': ['rbf', 'sigmoid', 'poly']}\n",
        "    model_params = {'class_weight': 'balanced', 'max_iter': 10, 'probability': True, 'random_state': 3}\n",
        "\n",
        "    # Inicializar o modelo SVM e GridSearchCV\n",
        "    model = SVC(**model_params)\n",
        "    clf = GridSearchCV(model, param_grid)\n",
        "\n",
        "    # Treinar o modelo\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    # Salvar o modelo treinado\n",
        "    joblib.dump(clf, SVM_PATH)\n",
        "    print(\"Modelo salvo em:\", SVM_PATH)\n",
        "\n",
        "# Exibir os melhores parâmetros do modelo\n",
        "print('Melhor estimador: ', clf.best_estimator_)\n",
        "print('Melhores parâmetros: ', clf.best_params_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F4v97rKu_Y8"
      },
      "source": [
        "**Check the accuracy score on Train & Test datasets(embeddings)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AhTXbedtbIB"
      },
      "source": [
        "# test data preparation\n",
        "X_test, y_test = np.copy(testEmbeds), np.array([CLASS_TO_IDX[label] for label in testLabels])\n",
        "print(f'X train embeds size: {X_test.shape}')\n",
        "print(f'Tagret train size: {y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwOt-SZ2vUCu"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "inds = range(88)\n",
        "train_acc = accuracy_score(clf.predict(X[inds]), y[inds])\n",
        "print(f'Accuracy score on train data: {train_acc:.3f}')\n",
        "\n",
        "test_acc = accuracy_score(clf.predict(X_test), y_test)\n",
        "print(f'Accuracy score on test data: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCjl65qN1jlJ"
      },
      "source": [
        "**Some functional for video preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNBM-rg17Dql"
      },
      "source": [
        "import cv2\n",
        "import imageio\n",
        "\n",
        "def toGif(path, dim):\n",
        "    gpath = ''.join(path.split('.')[:-1]) + '.gif'\n",
        "\n",
        "    with imageio.get_writer(gpath, mode='I') as writer:\n",
        "        frames = []\n",
        "        capture = cv2.VideoCapture(path)\n",
        "\n",
        "        i = 0\n",
        "        while True:\n",
        "            ret, frame = capture.read()\n",
        "            if not ret: break\n",
        "\n",
        "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            writer.append_data(cv2.resize(image, dim))\n",
        "            i += 1\n",
        "        print(f'Total frames: {i}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11RGIySdLMSC"
      },
      "source": [
        "# Create gifs from the existing videos in our path\n",
        "VIDEO_PATH = os.path.join(DATA_PATH, 'videos/')\n",
        "width, height = 640, 360\n",
        "\n",
        "mov1 = os.path.join(VIDEO_PATH, '1.mp4')\n",
        "toGif(mov1, (width, height))\n",
        "\n",
        "mov2 = os.path.join(VIDEO_PATH, '2.mp4')\n",
        "toGif(mov2, (width, height))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbcI16NbOXYd"
      },
      "source": [
        "**Bounding boxes can overlap, so define some function to avoid duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atUqnp3lOU7j"
      },
      "source": [
        "def diag(x1, y1, x2, y2):\n",
        "    return np.linalg.norm([x2 - x1, y2 - y1])\n",
        "\n",
        "def square(x1, y1, x2, y2):\n",
        "    return abs(x2 - x1) * abs(y2 - y1)\n",
        "\n",
        "def isOverlap(rect1, rect2):\n",
        "    x1, x2 = rect1[0], rect1[2]\n",
        "    y1, y2 = rect1[1], rect1[3]\n",
        "\n",
        "    x1_, x2_ = rect2[0], rect2[2]\n",
        "    y1_, y2_ = rect2[1], rect2[3]\n",
        "\n",
        "    if x1 > x2_ or x2 < x1_: return False\n",
        "    if y1 > y2_ or y2 < y1_: return False\n",
        "\n",
        "    rght, lft = x1 < x1_ < x2, x1_ < x1 < x2_\n",
        "    d1, d2 = 0, diag(x1_, y1_, x2_, y2_)\n",
        "    threshold = 0.5\n",
        "\n",
        "    if rght and y1 < y1_: d1 = diag(x1_, y1_, x2, y2)\n",
        "    elif rght and y1 > y1_: d1 = diag(x1_, y2_, x2, y1)\n",
        "    elif lft and y1 < y1_: d1 = diag(x2_, y1_, x1, y2)\n",
        "    elif lft and y1 > y1_: d1 = diag(x2_, y2_, x1, y1)\n",
        "\n",
        "    if d1 / d2 >= threshold and square(x1, y1, x2, y2) < square(x1_, y1_, x2_, y2_): return True\n",
        "    return False\n",
        "\n",
        "# Função principal para desenhar caixas\n",
        "def draw_box(draw, boxes, names, probs, min_p=0.95):\n",
        "    font = ImageFont.truetype(os.path.join(ABS_PATH, 'arial.ttf'), size=22)\n",
        "\n",
        "    not_overlap_inds = []\n",
        "    for i in range(len(boxes)):\n",
        "        not_overlap = True\n",
        "        for box2 in boxes:\n",
        "            if np.all(boxes[i] == box2): continue\n",
        "            not_overlap = not isOverlap(boxes[i], box2)\n",
        "            if not not_overlap: break\n",
        "        if not_overlap: not_overlap_inds.append(i)\n",
        "\n",
        "    boxes = [boxes[i] for i in not_overlap_inds]\n",
        "    probs = [probs[i] for i in not_overlap_inds]\n",
        "    for box, name, prob in zip(boxes, names, probs):\n",
        "        if prob >= min_p:\n",
        "            draw.rectangle(box.tolist(), outline=(255, 255, 255), width=5)\n",
        "            x1, y1, _, _ = box\n",
        "            # Usando getbbox para obter a largura e altura do texto\n",
        "            bbox = font.getbbox(f'{name}: {prob:.2f}')\n",
        "            text_width, text_height = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
        "            draw.rectangle(((x1, y1 - text_height), (x1 + text_width, y1)), fill='white')\n",
        "            draw.text((x1, y1 - text_height), f'{name}: {prob:.2f}', (24, 12, 30), font)\n",
        "\n",
        "    return boxes, probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnDLK-hxOoP5"
      },
      "source": [
        "**Functional for processing video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMxoNLxL6boe"
      },
      "source": [
        "standard_transform = transforms.Compose([\n",
        "                                transforms.Resize((160, 160)),\n",
        "                                np.float32,\n",
        "                                transforms.ToTensor(),\n",
        "                                fixed_image_standardization\n",
        "])\n",
        "\n",
        "def get_video_embedding(model, x):\n",
        "    embeds = model(x.to(device))\n",
        "    return embeds.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "def is_known_face(embedding, known_embeddings, threshold=0.8):\n",
        "    similarities = cosine_similarity([embedding], known_embeddings)\n",
        "    return similarities.max() >= threshold\n",
        "\n",
        "# def face_extract(model, clf, frame, boxes):\n",
        "#     names, prob = [], []\n",
        "#     if len(boxes):\n",
        "#         x = torch.stack([standard_transform(frame.crop(b)) for b in boxes])\n",
        "#         embeds = get_video_embedding(model, x)\n",
        "#         idx, prob = clf.predict(embeds), clf.predict_proba(embeds).max(axis=1)\n",
        "#         names = [IDX_TO_CLASS[idx_] for idx_ in idx]\n",
        "#     return names, prob\n",
        "\n",
        "def face_extract(model, clf, frame, boxes, known_embeddings, threshold=0.8):\n",
        "    names, probs = [], []\n",
        "    if len(boxes):\n",
        "        x = torch.stack([standard_transform(frame.crop(b)) for b in boxes])\n",
        "        embeds = get_video_embedding(model, x)  # Extrai as embeddings para cada rosto detectado\n",
        "\n",
        "        # Verifique se cada embedding corresponde a uma pessoa conhecida\n",
        "        for embed in embeds:\n",
        "            if is_known_face(embed, known_embeddings, threshold):\n",
        "                idx = clf.predict([embed])[0]\n",
        "                prob = clf.predict_proba([embed]).max()\n",
        "                names.append(IDX_TO_CLASS[idx])\n",
        "                probs.append(prob)\n",
        "            else:\n",
        "                # Marque como \"Desconhecido\" se a pessoa não for reconhecida\n",
        "                names.append(\"Desconhecido\")\n",
        "                probs.append(0.0)\n",
        "    return names, probs\n",
        "\n",
        "known_embeddings = trainEmbeds\n",
        "\n",
        "def preprocess_image(detector, face_extractor, clf, path, transform=None):\n",
        "    if not transform: transform = lambda x: x.resize((1280, 1280)) if (np.array(x.size) > 2000).all() else x\n",
        "    capture = Image.open(path).convert('RGB')\n",
        "    i = 0\n",
        "\n",
        "    # iframe = Image.fromarray(transform(np.array(capture)))\n",
        "    iframe = transform(capture)\n",
        "\n",
        "    boxes, probs = detector.detect(iframe)\n",
        "    if boxes is None: boxes, probs = [], []\n",
        "    names, prob = face_extract(face_extractor, clf, iframe, boxes, known_embeddings, threshold=0.8)\n",
        "\n",
        "    frame_draw = iframe.copy()\n",
        "    draw = ImageDraw.Draw(frame_draw)\n",
        "\n",
        "    boxes, probs = draw_box(draw, boxes, names, probs)\n",
        "    return frame_draw.resize((620, 480), Image.BILINEAR)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_video(detector, face_extractor, clf, path, transform=None, k=3):\n",
        "    frames = []\n",
        "    if not transform: transform = lambda x: x.resize((1280, 1280)) if (np.array(x.shape) > 2000).all() else x\n",
        "    capture = cv2.VideoCapture(path)\n",
        "    i = 0\n",
        "    while True:\n",
        "        ret, frame = capture.read()\n",
        "        if not ret: break\n",
        "\n",
        "        iframe = Image.fromarray(transform(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
        "\n",
        "        if (i + 1) % k:\n",
        "            boxes, probs = detector.detect(iframe)\n",
        "            if boxes is None: boxes, probs = [], []\n",
        "            names, prob = face_extract(face_extractor, clf, iframe, boxes, known_embeddings, threshold=0.8)\n",
        "\n",
        "        frame_draw = iframe.copy()\n",
        "        draw = ImageDraw.Draw(frame_draw)\n",
        "\n",
        "        boxes, probs = draw_box(draw, boxes, names, probs)\n",
        "        frames.append(frame_draw.resize((620, 480), Image.BILINEAR))\n",
        "        i += 1\n",
        "\n",
        "    print(f'Total frames: {i}')\n",
        "    return frames\n",
        "\n",
        "def framesToGif(frames, path):\n",
        "    with imageio.get_writer(path, mode='I') as writer:\n",
        "        for frame in tqdm.tqdm(frames):\n",
        "            writer.append_data(np.array(frame))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h45iPJFJlwqq"
      },
      "source": [
        "**Define our models and parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stp7QjVpXDy6"
      },
      "source": [
        "from PIL import ImageFont\n",
        "\n",
        "\n",
        "k = 3 # each k image will be processed by networks\n",
        "font = ImageFont.truetype(os.path.join(ABS_PATH, 'arial.ttf'), size=22)\n",
        "\n",
        "mtcnn = MTCNN(keep_all=True, min_face_size=70, device=device)\n",
        "model = InceptionResnetV1(pretrained='vggface2', dropout_prob=0.6, device=device).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yJgxDlhl417"
      },
      "source": [
        "**Process video and save to gif**\n",
        "\n",
        "# > Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnMVKs8NgIIF"
      },
      "source": [
        "%%time\n",
        "print('Processing mov1: ')\n",
        "frames = preprocess_video(mtcnn, model, clf, mov1)\n",
        "mov1_aug = os.path.join(VIDEO_PATH, '1.gif')\n",
        "framesToGif(frames, mov1_aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA_Y4QJakQHh"
      },
      "source": [
        "%%time\n",
        "print('Processing mov2: ')\n",
        "frames = preprocess_video(mtcnn, model, clf, mov2)\n",
        "mov2_aug = os.path.join(VIDEO_PATH, '2.gif')\n",
        "framesToGif(frames, mov2_aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu8LuMSwpCKV"
      },
      "source": [
        "**Some examples**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kTHk40KmEDI"
      },
      "source": [
        "![image](https://drive.google.com/uc?export=view&id=15fSxB0Z9lUInaTgEHsFqgYp5XdkbVTRd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb9zIItemdsK"
      },
      "source": [
        "![image](https://drive.google.com/uc?export=view&id=1KHCNLFnM4vCxWAEB78CzN-3nQMTTAdqc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfOEnBmY1ErF"
      },
      "source": [
        "**Some photos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ2MZRq_kbWJ"
      },
      "source": [
        "ADD_DATA = os.path.join(DATA_PATH, 'images')\n",
        "\n",
        "frame = preprocess_image(mtcnn, model, clf, os.path.join(ADD_DATA, '1.jpeg'))\n",
        "frame.save(os.path.join(ADD_DATA, '1_augs'), 'gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajld39bD00tM"
      },
      "source": [
        "![image](https://drive.google.com/uc?export=view&id=1KTpgQFNH7aBn6ru7e6zR8RLyNy_onL6G)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVXc-_gnRZ-G"
      },
      "source": [
        "ADD_DATA = os.path.join(DATA_PATH, 'images')\n",
        "\n",
        "frame = preprocess_image(mtcnn, model, clf, os.path.join(ADD_DATA, '2.jpeg'))\n",
        "frame.save(os.path.join(ADD_DATA, '2_aug'), 'gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.12.0 # Certifique-se de instalar a versão correta do TensorFlow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wBuFdYWLi-l5",
        "outputId": "a72928b7-10c9-4b42-e572-44836f6a7846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.11.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.44.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.16 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.22.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "facenet-pytorch 2.6.0 requires numpy<2.0.0,>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.12.0 which is incompatible.\n",
            "xarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ddc59a128e2c48d98560f1542ad2a980"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Carregar o modelo SVM treinado\n",
        "svm_model = joblib.load(SVM_PATH)  # Usa o caminho salvo como `SVM_PATH`\n",
        "\n",
        "# Dividir os embeddings e rótulos em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(trainEmbeds, trainLabels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Obter previsões do SVM para que a rede neural aprenda a imitar o SVM\n",
        "y_train_pred = svm_model.predict(X_train)\n",
        "y_test_pred = svm_model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"y_train_pred\", y_train_pred)\n",
        "\n",
        "print('y_test_pred', y_test_pred)\n",
        "\n",
        "# Converter rótulos para categóricos (necessário para a rede neural)\n",
        "y_train_cat = to_categorical(y_train_pred)\n",
        "y_test_cat = to_categorical(y_test_pred)\n"
      ],
      "metadata": {
        "id": "lH6hQWJeocUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Definir uma rede neural simples\n",
        "model_nn = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(y_train_cat.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo com as saídas do SVM como rótulos\n",
        "model_nn.fit(X_train, y_train_cat, epochs=10, validation_data=(X_test, y_test_cat))\n",
        "\n",
        "# Converter o modelo Keras para TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_nn)\n",
        "# Quantização (opcional) para otimização em dispositivos móveis\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Salvar o modelo TFLite\n",
        "tflite_path = os.path.join(os.path.dirname(SVM_PATH), \"model2.tflite\")\n",
        "with open(tflite_path, \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Modelo salvo como model.tflite em:\", tflite_path)\n"
      ],
      "metadata": {
        "id": "E5CGcNsAo8ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carregar o modelo .tflite salvo na mesma pasta que o SVM_PATH\n",
        "tflite_path = os.path.join(os.path.dirname(SVM_PATH), \"model2.tflite\")\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Obter informações sobre os tensores de entrada e saída do modelo TFLite\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Função para fazer previsões com o modelo TFLite\n",
        "def predict_tflite(input_data):\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return output_data\n",
        "\n",
        "# Previsões com o modelo SVM para comparação\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "# Previsões com o modelo TFLite\n",
        "tflite_predictions = []\n",
        "for i in range(len(X_test)):\n",
        "    input_data = np.array([X_test[i]], dtype=np.float32)\n",
        "    tflite_pred = predict_tflite(input_data)\n",
        "    tflite_predictions.append(np.argmax(tflite_pred))  # Obter a classe de maior probabilidade\n",
        "\n",
        "# Converter `y_test` para índices inteiros usando `CLASS_TO_IDX`\n",
        "y_test_numeric = np.array([CLASS_TO_IDX[label] for label in y_test])\n",
        "\n",
        "# Comparar previsões dos dois modelos e calcular precisão\n",
        "print(\"Primeiras 10 previsões do SVM:\", svm_predictions[:10])\n",
        "print(\"Primeiras 10 previsões do modelo TFLite:\", tflite_predictions[:10])\n",
        "\n",
        "# Calcular a precisão do modelo TFLite\n",
        "tflite_accuracy = accuracy_score(y_test_numeric, tflite_predictions)\n",
        "print(\"Precisão do modelo TFLite:\", tflite_accuracy)\n"
      ],
      "metadata": {
        "id": "kOtx2TWAQtea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# ... (seu código principal) ...\n",
        "\n",
        "# Carregue o modelo .tflite usando o caminho definido no seu código\n",
        "tflite_path = os.path.join(os.path.dirname(SVM_PATH), \"model2.tflite\")\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Obtenha os detalhes do tensor de entrada\n",
        "input_details = interpreter.get_input_details()\n",
        "\n",
        "# Obtenha os detalhes do tensor de saída\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Imprima as formas dos tensores de entrada e saída\n",
        "print(\"Input shape:\", input_details[0]['shape'])\n",
        "print(\"Output shape:\", output_details[0]['shape'])\n",
        "\n",
        "# ... (restante do seu código principal) ..."
      ],
      "metadata": {
        "id": "np9hBWxTRDwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQWbXoQa1OM7"
      },
      "source": [
        "![image](https://drive.google.com/uc?export=view&id=1KTqSyyRhemUhoD-1naNKiePZXt8Vfu1j)"
      ]
    }
  ]
}